{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca7b775",
   "metadata": {},
   "source": [
    "# fetch provider Data and save in folder -DO not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c132bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting provider data download...\n",
      "\n",
      "[✓] Saved data for Chiro to data-collection\\provider\\Chiro.json\n",
      "[✓] Saved data for Physio to data-collection\\provider\\Physio.json\n",
      "[✓] Saved data for Massage to data-collection\\provider\\Massage.json\n",
      "[✓] Saved data for MI to data-collection\\provider\\MI.json\n",
      "[✓] Saved data for Orthodontic to data-collection\\provider\\Orthodontic.json\n",
      "[✓] Saved data for Podiatry to data-collection\\provider\\Podiatry.json\n",
      "[✓] Saved data for Acupuncture to data-collection\\provider\\Acupuncture.json\n",
      "[✓] Saved data for Speech to data-collection\\provider\\Speech.json\n",
      "[✓] Saved data for Chiropody to data-collection\\provider\\Chiropody.json\n",
      "[✓] Saved data for Naturopathy to data-collection\\provider\\Naturopathy.json\n",
      "[✓] Saved data for Psychology to data-collection\\provider\\Psychology.json\n",
      "[✓] Saved data for Dental to data-collection\\provider\\Dental.json\n",
      "[✓] Saved data for Osteopath to data-collection\\provider\\Osteopath.json\n",
      "[✓] Saved data for Audiologist to data-collection\\provider\\Audiologist.json\n",
      "[✓] Saved data for Athletic to data-collection\\provider\\Athletic.json\n",
      "[✓] Saved data for Dietician to data-collection\\provider\\Dietician.json\n",
      "[✓] Saved data for Homeopath to data-collection\\provider\\Homeopath.json\n",
      "[✓] Saved data for Occupational to data-collection\\provider\\Occupational.json\n",
      "[✓] Saved data for Drug to data-collection\\provider\\Drug.json\n",
      "[✓] Saved data for MasterOfSocialWork to data-collection\\provider\\MasterOfSocialWork.json\n",
      "[✓] Saved data for SocialWorker to data-collection\\provider\\SocialWorker.json\n",
      "[✓] Saved data for Vision to data-collection\\provider\\Vision.json\n",
      "[✓] Saved data for Psychotherapist to data-collection\\provider\\Psychotherapist.json\n",
      "[✓] Saved data for Counselling to data-collection\\provider\\Counselling.json\n",
      "\n",
      "[INFO] All provider types processed.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# List of provider types\n",
    "PROVIDER_TYPES = [\n",
    "    \"Chiro\", \"Physio\", \"Massage\", \"MI\", \"Orthodontic\", \"Podiatry\",\n",
    "    \"Acupuncture\", \"Speech\", \"Chiropody\", \"Naturopathy\", \"Psychology\",\n",
    "    \"Dental\", \"Osteopath\", \"Audiologist\", \"Athletic\", \"Dietician\",\n",
    "    \"Homeopath\", \"Occupational\", \"Drug\", \"MasterOfSocialWork\",\n",
    "    \"SocialWorker\", \"Vision\", \"Psychotherapist\", \"Counselling\"\n",
    "]\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path(\"data-collection/provider\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# API URL (base)\n",
    "BASE_URL = (\n",
    "    \"https://students-healthportal.securiancanada.ca/pmos-api-b2c/api/v1/Providers/search\"\n",
    "    \"?ProviderType={provider}&Latitude=43.4511&Longitude=-80.4926\"\n",
    "    \"&SourceLatitude=43.4511&SourceLongitude=-80.4926&SortingType=distance\"\n",
    "    \"&SearchType=ProviderType&Distance=30&PageNo=1&PageSize=200\"\n",
    "    \"&ProviderRating=&IsDelisted=&DirectBilling=\"\n",
    ")\n",
    "\n",
    "# Set your Bearer token here\n",
    "AUTH_TOKEN = \"eyJhbGciOiJSUzI1NiIsImtpZCI6IlVaNDc1ZE0wa0dXV2xKNFFOVzFWY0kzZkNJaUZpZ0tKa25abnlPbW9wY00iLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiI2NTgzNjg2Yi02Y2U1LTQ0MmQtYTU1My1iZjA3M2JjODdjMzIiLCJpc3MiOiJodHRwczovL2dzY3Byb2RiMmMuYjJjbG9naW4uY29tLzk5OGEwMzhlLThkNWMtNDE5Yi05NjYzLWViZTE1MDYxODE1MC92Mi4wLyIsImV4cCI6MTc0OTUyMzY3NywibmJmIjoxNzQ5NTIxODc3LCJzc28iOmZhbHNlLCJzdWIiOiI1Y2E5NDQ5MC0xNTgxLTQ2YWEtYTRkMS1iMGUzN2U2MjYzNzciLCJuYW1lIjoiZHBhdGVsNjQzNUBjb25lc3RvZ2FjLm9uLmNhIiwidGZwIjoiQjJDXzFBX1BNX1NpZ25JblNpZ25VcCIsInRpZCI6Ijk5OGEwMzhlLThkNWMtNDE5Yi05NjYzLWViZTE1MDYxODE1MCIsImNsaWVudF9pZCI6InBtb3MtZnJvbnRlbmQtZ3NjIiwiY2xpZW50X2N0eXBlIjoiUE0iLCJjc2lkIjoiY2UxYTdiNzItM2QxMC00ZTE2LWJiNjQtMWRiNzFkMWUyMTFhIiwibm9uY2UiOiIzYzY3OWZjMC1kZTA2LTQ4MjgtYjdhYy1lNzEzMTVhOGUyYjAiLCJzY3AiOiJwbW9zLWFwaSBkaWdpdGFsLXByb2R1Y3RzLWFwaSIsImF6cCI6ImU0YmM4ZWExLTM2YmYtNDhiMC05Mjg2LWVmMTdkNTFjYzc3YiIsInZlciI6IjEuMCIsImlhdCI6MTc0OTUyMTg3N30.ZRtAob-rojdnB8-p3WMU3QAUcqrIvrOThihE9AcFqQ3X33AHkRSpteGgCgbmPeyKwXyhHmXWSMmd88mvvBbx_29PJU4boryVCb8_3C1Mjx9I-njVxz91OXhOMJDGM4sHeQ7HXw_NPVg5gYd9TrngCAZYQkGfJiyP_aCnpOpzfv7BaZUbgNgCHkQ7py_5kW9ePGjKw-GRn3IZVXiekxwFaKIhJO5bCH7RMNJYrqvUAI_yPGNF_QaJRwNlPhbukvgmUSNKGsjKRs7waGTt-8EPZ3v9yUsVOgIHsU9hTgOTG1ZA5RN8C5q8pSQgP6qMHusdkvf0XC2n2DBz26gIqQU-GA\"\n",
    "\n",
    "# HTTP headers with authorization\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "def fetch_and_save(provider_type: str):\n",
    "    \"\"\"Fetch data for a provider type and save as JSON file.\"\"\"\n",
    "    url = BASE_URL.format(provider=provider_type)\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Save response to file\n",
    "        file_path = OUTPUT_DIR / f\"{provider_type}.json\"\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        print(f\"[✓] Saved data for {provider_type} to {file_path}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"[ERROR] Failed to fetch {provider_type}: {e}\")\n",
    "\n",
    "def main():\n",
    "    print(\"[INFO] Starting provider data download...\\n\")\n",
    "    for provider in PROVIDER_TYPES:\n",
    "        fetch_and_save(provider)\n",
    "    print(\"\\n[INFO] All provider types processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc292a84",
   "metadata": {},
   "source": [
    "## provider ->insert data in to Database with emebbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import psycopg2\n",
    "from psycopg2.extras import Json\n",
    "from psycopg2 import sql\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- CONFIG ---\n",
    "CLEAN_FOLDER = \"data-collection/provider\"\n",
    "DB_PARAMS = {\n",
    "    \"dbname\":   \"HealthCareTest\",\n",
    "    \"user\":     \"Deep\",\n",
    "    \"password\": \"Deep@0506\",\n",
    "    \"host\":     \"localhost\",\n",
    "    \"port\":     5432,\n",
    "}\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "VECTOR_DIM = 384  # embedding size for all-MiniLM-L6-v2\n",
    "\n",
    "# --- load embedding model once ---\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# --- connect & ensure table exists ---\n",
    "conn = psycopg2.connect(**DB_PARAMS)\n",
    "cur = conn.cursor()\n",
    "# enable pgvector extension\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "# create providers table with new schema\n",
    "cur.execute(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS tbl_providers (\n",
    "  id SERIAL PRIMARY KEY,\n",
    "  provider_id BIGINT UNIQUE NOT NULL,\n",
    "  provider_name TEXT NOT NULL,\n",
    "  address TEXT,\n",
    "  phone_number TEXT,\n",
    "  latitude DOUBLE PRECISION,\n",
    "  longitude DOUBLE PRECISION,\n",
    "  opening_hours JSONB,\n",
    "  website TEXT,\n",
    "  description TEXT,\n",
    "  embeddings VECTOR({VECTOR_DIM}) NOT NULL\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# --- helper to build description & fields ---\n",
    "def build_record(rec: dict) -> dict:\n",
    "    # Basic fields\n",
    "    pid = rec.get(\"providerId\")\n",
    "    name = rec.get(\"providerName\", \"\").strip()\n",
    "    # address components\n",
    "    line1 = rec.get(\"addressFirstLine\", \"\").strip()\n",
    "    line2 = rec.get(\"addressSecondLine\") or \"\"\n",
    "    city = rec.get(\"city\", \"\").strip()\n",
    "    province = rec.get(\"province\", \"\").strip()\n",
    "    postal = rec.get(\"postalCode\", \"\").strip()\n",
    "    parts = [p for p in [line1, line2, city, province, postal] if p]\n",
    "    address = \", \".join(parts)\n",
    "    phone = rec.get(\"phoneNumber\") or \"\"\n",
    "    lat = rec.get(\"latitude\")\n",
    "    lon = rec.get(\"longitude\")\n",
    "    gpd = rec.get(\"googlePlaceData\") or {}\n",
    "    opening = gpd.get(\"opening_hours\")\n",
    "    website = gpd.get(\"website\") or gpd.get(\"formatted_phone_number\") or \"\"\n",
    "    # compose textual description\n",
    "    ptype = rec.get(\"providerTypeDescription\", {}).get(\"en\", \"\").strip()\n",
    "    desc = (\n",
    "        f\"{name} is a {ptype} provider located at {address}. \"\n",
    "        f\"Contact via phone {phone or 'N/A'}. Website: {website or 'N/A'}.\"\n",
    "    )\n",
    "    # encode description\n",
    "    emb = model.encode(desc).tolist()\n",
    "    return {\n",
    "        \"provider_id\": pid,\n",
    "        \"provider_name\": name,\n",
    "        \"address\": address,\n",
    "        \"phone_number\": phone,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"opening_hours\": opening,\n",
    "        \"website\": website,\n",
    "        \"description\": desc,\n",
    "        \"embeddings\": emb\n",
    "    }\n",
    "\n",
    "# --- process each JSON file ---\n",
    "for path in glob.glob(os.path.join(CLEAN_FOLDER, \"*.json\")):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        payload = json.load(f)\n",
    "    for rec in payload.get(\"results\", []):\n",
    "        record = build_record(rec)\n",
    "        # prepare embedding literal\n",
    "        emb_literal = \"[\" + \",\".join(str(x) for x in record['embeddings']) + \"]\"\n",
    "        # insert or update\n",
    "        cur.execute(sql.SQL(\"\"\"\n",
    "            INSERT INTO tbl_providers (\n",
    "                provider_id, provider_name, address, phone_number,\n",
    "                latitude, longitude, opening_hours, website,\n",
    "                description, embeddings\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s::jsonb, %s, %s, %s::vector)\n",
    "            ON CONFLICT (provider_id) DO UPDATE SET\n",
    "                provider_name = EXCLUDED.provider_name,\n",
    "                address = EXCLUDED.address,\n",
    "                phone_number = EXCLUDED.phone_number,\n",
    "                latitude = EXCLUDED.latitude,\n",
    "                longitude = EXCLUDED.longitude,\n",
    "                opening_hours = EXCLUDED.opening_hours,\n",
    "                website = EXCLUDED.website,\n",
    "                description = EXCLUDED.description,\n",
    "                embeddings = EXCLUDED.embeddings;\n",
    "        \"\"\"), (\n",
    "            record['provider_id'],\n",
    "            record['provider_name'],\n",
    "            record['address'],\n",
    "            record['phone_number'],\n",
    "            record['latitude'],\n",
    "            record['longitude'],\n",
    "            Json(record['opening_hours']),\n",
    "            record['website'],\n",
    "            record['description'],\n",
    "            emb_literal\n",
    "        ))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"✅ Imported all JSON files with new schema and embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c4c1d7",
   "metadata": {},
   "source": [
    "## clinical_data-> insert data into database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import json\n",
    "import psycopg2\n",
    "from psycopg2.extras import register_default_jsonb\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ─── Configuration ──────────────────────────────────────────────────────────────\n",
    "CLEAN_FOLDER = \"data-collection/clinical_data\"\n",
    "DB_PARAMS = {\n",
    "    \"dbname\":   \"HealthCareTest\",\n",
    "    \"user\":     \"Deep\",\n",
    "    \"password\": \"Deep@0506\",\n",
    "    \"host\":     \"localhost\",\n",
    "    \"port\":     5432,\n",
    "}\n",
    "TABLE_NAME = \"healthcare_services\"\n",
    "\n",
    "# ─── Connect and (re)create table ───────────────────────────────────────────────\n",
    "conn = psycopg2.connect(**DB_PARAMS)\n",
    "register_default_jsonb(conn)\n",
    "register_vector(conn)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "# Drop+recreate so we get the new schema every time\n",
    "cur.execute(f\"\"\"\n",
    "DROP TABLE IF EXISTS {TABLE_NAME};\n",
    "CREATE TABLE {TABLE_NAME} (\n",
    "    id                SERIAL PRIMARY KEY,\n",
    "    name              TEXT       NOT NULL,\n",
    "    description       TEXT,\n",
    "    latitude          DOUBLE PRECISION,\n",
    "    longitude         DOUBLE PRECISION,\n",
    "    address           TEXT,\n",
    "    contact_info      TEXT,\n",
    "    languages         TEXT[],\n",
    "    metadata          JSONB,\n",
    "    embedding         VECTOR(384)\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# ─── Load the embedder ──────────────────────────────────────────────────────────\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ─── Process each file ──────────────────────────────────────────────────────────\n",
    "for fname in os.listdir(CLEAN_FOLDER):\n",
    "    if not fname.lower().endswith(\".json\"):\n",
    "        continue\n",
    "    with open(os.path.join(CLEAN_FOLDER, fname), \"r\", encoding=\"utf8\") as f:\n",
    "        records = json.load(f)\n",
    "\n",
    "    for rec in records:\n",
    "        name        = rec.get(\"name\",\"\")\n",
    "        # pick whichever makes sense as your RAG input\n",
    "        description = rec.get(\"description_of_this\") or rec.get(\"comment\",\"\")\n",
    "\n",
    "        # extract lat/lon\n",
    "        pos = rec.get(\"locations\", [{}])[0].get(\"position\", {})\n",
    "        latitude  = pos.get(\"latitude\")\n",
    "        longitude = pos.get(\"longitude\")\n",
    "\n",
    "        # build a flat address string\n",
    "        addr = rec.get(\"locations\", [{}])[0].get(\"address\", {})\n",
    "        address = \", \".join(addr.get(\"line\",[]) +\n",
    "                            [addr.get(\"city\",\"\"), addr.get(\"state\",\"\"), addr.get(\"postalCode\",\"\")])\n",
    "\n",
    "        contact_info = rec.get(\"contact_info\",\"\")\n",
    "\n",
    "        # languages array\n",
    "        languages = rec.get(\"communication\", [])\n",
    "\n",
    "        # slim metadata (no big HTML/text fields)\n",
    "        md = {k: v for k,v in rec.items()\n",
    "              if k not in (\"text\",\"comment\",\"description_of_this\")}\n",
    "\n",
    "        # compute embedding\n",
    "        vec = model.encode(description, convert_to_numpy=True).tolist()\n",
    "\n",
    "        # insert\n",
    "        cur.execute(f\"\"\"\n",
    "            INSERT INTO {TABLE_NAME}\n",
    "              (name, description, latitude, longitude,\n",
    "               address, contact_info, languages, metadata, embedding)\n",
    "            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "            ON CONFLICT DO NOTHING;\n",
    "        \"\"\", (\n",
    "            name, description, latitude, longitude,\n",
    "            address, contact_info, languages, json.dumps(md), vec\n",
    "        ))\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"Done. Table now has separate lat/lon, languages, and slim metadata.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6677d6",
   "metadata": {},
   "source": [
    "## Lab data insert into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import psycopg2\n",
    "from psycopg2.extras import Json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- CONFIG ---\n",
    "JSON_PATH   = \"data-collection/Lab_data/Lab.json\"\n",
    "CSV_PATH    = \"data-collection/Lab_data/lifelabs_waterloo_full.csv\"\n",
    "DB_PARAMS   = {\n",
    "    \"dbname\":   \"HealthCareTest\",\n",
    "    \"user\":     \"Deep\",\n",
    "    \"password\": \"Deep@0506\",\n",
    "    \"host\":     \"localhost\",\n",
    "    \"port\":     5432,\n",
    "}\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "VECTOR_DIM  = 384  # dimension for all-MiniLM-L6-v2\n",
    "\n",
    "# 1) load embedding model\n",
    "model = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "# 2) connect to Postgres\n",
    "conn = psycopg2.connect(**DB_PARAMS)\n",
    "cur  = conn.cursor()\n",
    "\n",
    "# 3) ensure pgvector extension & table exist\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "\n",
    "cur.execute(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS lab_locations (\n",
    "  name           TEXT         PRIMARY KEY,\n",
    "  street         TEXT,\n",
    "  city           TEXT,\n",
    "  province       CHAR(2),\n",
    "  postal_code    VARCHAR(10),\n",
    "  phone          VARCHAR(20),\n",
    "  latitude       NUMERIC(9,6),\n",
    "  longitude      NUMERIC(9,6),\n",
    "  instructions   TEXT,\n",
    "  embeddings     VECTOR({VECTOR_DIM})\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# 4) read CSV into a map by name\n",
    "csv_map = {}\n",
    "with open(CSV_PATH, newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        csv_map[row[\"name\"].strip()] = row\n",
    "\n",
    "# 5) load JSON entries\n",
    "with open(JSON_PATH, encoding=\"utf-8\") as f:\n",
    "    lab_data = json.load(f)\n",
    "\n",
    "# 6) upsert each entry\n",
    "for ent in lab_data.get(\"entity\", []):\n",
    "    name = ent.get(\"pscName\", \"\").strip()\n",
    "    csv_row = csv_map.get(name)\n",
    "    if not csv_row:\n",
    "        print(f\"⚠️  No matching CSV for '{name}', skipping\")\n",
    "        continue\n",
    "\n",
    "    # extract static & dynamic fields\n",
    "    street = ent[\"locationAddress\"][\"street\"]\n",
    "    city   = ent[\"locationAddress\"][\"city\"]\n",
    "    prov   = ent[\"locationAddress\"][\"province\"]\n",
    "    postal = ent[\"locationAddress\"][\"postalCode\"]\n",
    "    phone  = ent.get(\"phone\", \"\").strip() or \"N/A\"\n",
    "\n",
    "    hours     = csv_row[\"hours_today\"].strip()\n",
    "    appt      = csv_row[\"earliest_appt\"].strip()\n",
    "    wait_min  = csv_row[\"walkin_wait_min\"].strip()\n",
    "    instr     = csv_row[\"instructions\"].strip()\n",
    "\n",
    "    # build description string (for embedding)\n",
    "    desc = (\n",
    "        f\"{name} at {street}, {city}, {prov} {postal}. \"\n",
    "        f\"Phone: {phone}. Hours today: {hours}. \"\n",
    "        f\"Earliest appointment: {appt}. \"\n",
    "        f\"Current wait time: {wait_min} minutes. \"\n",
    "        f\"Instructions: {instr}\"\n",
    "    )\n",
    "\n",
    "    # compute embedding\n",
    "    emb = model.encode(desc).tolist()\n",
    "    # format for SQL parameter\n",
    "    emb_str = \"[\" + \",\".join(f\"{x:.6f}\" for x in emb) + \"]\"\n",
    "\n",
    "    # attempt UPDATE first\n",
    "    cur.execute(\"\"\"\n",
    "        UPDATE lab_locations\n",
    "           SET street       = %s,\n",
    "               city         = %s,\n",
    "               province     = %s,\n",
    "               postal_code  = %s,\n",
    "               phone        = %s,\n",
    "               instructions = %s,\n",
    "               embeddings   = %s::vector\n",
    "         WHERE name = %s;\n",
    "    \"\"\", (\n",
    "        street, city, prov, postal, phone,\n",
    "        instr, emb_str,\n",
    "        name\n",
    "    ))\n",
    "\n",
    "    if cur.rowcount == 0:\n",
    "        # INSERT if no existing row\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO lab_locations\n",
    "              (name, street, city, province, postal_code,\n",
    "               phone, latitude, longitude,\n",
    "               instructions, embeddings)\n",
    "            VALUES\n",
    "              (%s, %s, %s, %s, %s,\n",
    "               %s, %s, %s,\n",
    "               %s, %s::vector);\n",
    "        \"\"\", (\n",
    "            name,\n",
    "            street, city, prov, postal,\n",
    "            phone,\n",
    "            ent[\"locationCoordinate\"][\"latitude\"],\n",
    "            ent[\"locationCoordinate\"][\"longitude\"],\n",
    "            instr,\n",
    "            emb_str\n",
    "        ))\n",
    "    print(f\"✔ Upserted '{name}'\")\n",
    "\n",
    "# commit and close\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"✅ Done loading lab_locations.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
